{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4804a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10724/4180047725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\fontconfig_pattern.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pyparsing import (Literal, ZeroOrMore, Optional, Regex, StringEnd,\n\u001b[0m\u001b[0;32m     16\u001b[0m                        ParseException, Suppress)\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyparsing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_builtin_exprs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcore_builtin_exprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_builtin_exprs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhelper_builtin_exprs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyparsing\\helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[0m_htmlEntityMap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m common_html_entity = Regex(\"&(?P<entity>\" + \"|\".join(_htmlEntityMap) + \");\").set_name(\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;34m\"common HTML entity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyparsing\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pattern, flags, as_group_list, as_match, asGroupList, asMatch)\u001b[0m\n\u001b[0;32m   2881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2882\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2883\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2884\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2885\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0msre_constants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[0;32m    444\u001b[0m                            not nested and not items))\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    837\u001b[0m                                    source.tell() - start)\n\u001b[0;32m    838\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m                 \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosegroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m             \u001b[0msubpatternappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSUBPATTERN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_flags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdel_flags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mclosegroup\u001b[1;34m(self, gid, p)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclosegroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupwidths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgid\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupwidths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mgetwidth\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mav\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                     \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mgetwidth\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[0mlo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlo\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_REPEATCODES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mlo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlo\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gzip \n",
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import os\n",
    "import vec_tools\n",
    "import word_tools\n",
    "import statistics\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f1cc0",
   "metadata": {},
   "source": [
    "# Create/load domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dir =  \"G:/My Drive/KU/Thesis/data/domains/\" \n",
    "domain_dic = {}\n",
    "\n",
    "garg_lists = [\"occupations1950.txt\", \"adjectives_appearance.txt\",  'adjectives_appearance.txt',\n",
    " 'adjectives_intelligencegeneral.txt', 'adjectives_otherization.txt', 'adjectives_princeton.txt',\n",
    " 'adjectives_sensitive.txt', 'adjectives_williamsbest.csv', 'adjectives_williamsbest.txt',\n",
    " 'personalitytraits_original.txt', 'occupations1950_professional.txt']\n",
    "\n",
    "for dic in garg_lists:\n",
    "    li = open(f\"G:/My Drive/KU/Thesis/data/garg/{dic}\", encoding=\"utf-8\").readlines()\n",
    "    domain_dic[dic[:-4]] = [el.strip() for el in li]\n",
    "\n",
    "wiki_lists = ['sports','music_genres','lit_genres','us_cities','uk_cities',\n",
    "               'countries','art_movs','hobbies','subcultures'] \n",
    "for lst in wiki_lists:\n",
    "    domain_dic[lst] = word_tools.load_list(f\"{lst_dir}/wiki/{lst}_wiki.txt\")\n",
    "    \n",
    "manual_lists = [ 'virtues.txt', 'vices.txt', 'genres.txt', 'emotions.txt', 'housing.txt', 'housing_uk.txt',\n",
    " 'clothing.txt', 'white_trash.txt', 'old_rich.txt', 'new_rich.txt', 'u.txt', 'new_u.txt', 'non_u.txt',\n",
    " 'refined.txt', 'unrefined.txt']\n",
    "\n",
    "for dic in manual_lists:\n",
    "    li = open(f\"G:/My Drive/KU/Thesis/data/domains/{dic}\").readlines()\n",
    "    domain_dic[dic[:-4]] = [el.strip() for el in li]\n",
    "domain_dic.keys()\n",
    "\n",
    "domain_dic[\"goc_genres\"] = [\"hiphop\", \"rap\", \"bluegrass\", \"opera\", \"jazz\", \"techno\", \"punk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060940dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups =['Iso_occupations.xlsx','standard_occupations_uk_incomplete.xlsx','occupations_1950_categorised.xlsx','vices_virtues.xlsx','u_non_u.xlsx','old_rich_new_rich.xlsx','emerging_traditional_genres.xlsx']\n",
    "os.chdir(\"G:/My Drive/KU/Thesis/data/domains/dicts/\")\n",
    "os.listdir()\n",
    "for group in groups: \n",
    "    domain_dic[group[:-5]] = vec_tools.load_domain_dic(f\"G:/My Drive/KU/Thesis/data/domains/dicts/{group}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aea92c",
   "metadata": {},
   "source": [
    "# Almighty iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20eed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllDecsIterator():\n",
    "    def __init__(self, coll, dims, kv, test=False):\n",
    "        self.coll = coll\n",
    "        self.dims = dims\n",
    "        self.stereotypes = {}\n",
    "        self.test=test\n",
    "        self.kv = kv\n",
    "        \n",
    "    def iterate(self):\n",
    "        self.input_dir = f\"D:/google_ngrams/vectors/{coll}/\"\n",
    "        decades_dict = OrderedDict()\n",
    "        if self.test == True:\n",
    "            rng = 2\n",
    "        else: \n",
    "            rng = 10\n",
    "        for i in range(rng):\n",
    "            decades_dict[str(1900+10*i)] = str(1900+10*i)+'_model'\n",
    "        self.wvs = vec_tools.load_wvs(decades_dict, self.input_dir, kv=self.kv)\n",
    "        self.ants = {dec : {} for dec, val in self.wvs.items()}\n",
    "        self.projs = {dec : {} for dec, val in self.wvs.items()}\n",
    "        self.dim_vecs = {dec : {} for dec, val in self.wvs.items()}\n",
    "        self.angles = {dec : {} for dec, val in self.wvs.items()}\n",
    "        self.norm_matrix = {dec : {} for dec, val in self.wvs.items()}\n",
    "        self.stereotypes = {dec : {} for dec, val in self.wvs.items()}\n",
    "        \n",
    "        for dec, wv in self.wvs.items():\n",
    "            matrix = wv.get_normed_vectors()\n",
    "            self.norm_matrix[dec] = vec_tools.normify_matrix(matrix)\n",
    "\n",
    "            for dim in self.dims:\n",
    "                self.ants[dec][dim] = pd.read_csv(f\"G:/My Drive/KU/Thesis/data/word_pairs/{dim}_antonyms_goc.csv\", header = None, names = (\"pos_ant\", \"neg_ant\"))\n",
    "                self.ants[dec][dim] = self.ants[dec][dim].rename(columns= {\"pos_ant\":self.ants[dec][dim].iloc[0,0],\"neg_ant\":self.ants[dec][dim].iloc[0,1]})\n",
    "                self.dim_vecs[dec][dim] = vec_tools.create_dim_avg(wv, self.ants[dec][dim])\n",
    "                self.projs[dec][dim] = vec_tools.proj_dim(self.dim_vecs[dec][dim], self.norm_matrix[dec])\n",
    "               # print(dec, dim, self.projs[dec][dim])\n",
    "            \n",
    "            #Calculate angles between dimensions per decade\n",
    "            self.angles[dec] = {dim : {} for dim in self.dims}\n",
    "            for dim1 in self.dims:\n",
    "                for dim2 in self.dims:\n",
    "                    angle = vec_tools.vector_angle(self.dim_vecs[dec][dim1], self.dim_vecs[dec][dim2])\n",
    "                    self.angles[dec][dim1][dim2] = angle\n",
    "            self.angles[dec] = pd.DataFrame(self.angles[dec])\n",
    "    \n",
    "    def stability_through_time(self, n=50):\n",
    "        '''Retuns dictionary of dictionaries that shows the difference the average of\n",
    "        the distances between each stop word for each decade'''\n",
    "        \n",
    "        print(\"Calculating stability through time...\")\n",
    "        words = [\"f_words\", \"rand_words\"]\n",
    "        w_lists = {}\n",
    "        \n",
    "        w_lists[\"f_words\"] =  stopwords.words('english')\n",
    "        self.vocab_size = self.norm_matrix[\"1900\"].shape[0]\n",
    "        rand_inds = [random.randint(0, self.vocab_size) for i in range(n)]\n",
    "        rand_words = [self.wvs[\"1900\"].index_to_key[ind] for ind in rand_inds]\n",
    "        w_lists[\"rand_words\"] = []\n",
    "        for word in rand_words:\n",
    "            for dec, wv in self.wvs.items():\n",
    "                try:\n",
    "                    vec = wv[word]\n",
    "                except:\n",
    "                    break\n",
    "            w_lists[\"rand_words\"].append(word)\n",
    "        \n",
    "        dists = {}\n",
    "        avg_dists = {}\n",
    "        diffs = {}\n",
    "        for w_list in words:\n",
    "            dists[w_list] = {}\n",
    "            avg_dists[w_list] = {}\n",
    "            for dec, wv in self.wvs.items():\n",
    "                dists[w_list][dec] = {}\n",
    "                for i, fword_1 in enumerate(w_lists[w_list]):\n",
    "                    dists[w_list][dec][fword_1] = {}\n",
    "                    for fword_2 in w_lists[w_list][i:]:\n",
    "                        try:\n",
    "                            wv_1, wv_2 = wv[fword_1], wv[fword_2]\n",
    "                            dist = np.linalg.norm(wv_1 - wv_2)\n",
    "                            dists[w_list][dec][fword_1][fword_2] = dist\n",
    "                        except:\n",
    "                            continue\n",
    "                #avg_dists[dec] = np.mean(dists[dec].values)\n",
    "            diffs[w_list] = {dec: {} for dec, wv in self.wvs.items()}\n",
    "            for dec_1, wv in self.wvs.items():\n",
    "                for dec_2, wv in self.wvs.items():\n",
    "                    diffs[w_list][dec_1][dec_2] = []\n",
    "                    for i, fword_1 in enumerate(w_lists[w_list]):\n",
    "                        for fword_2 in w_lists[w_list][i:]:\n",
    "                            try:\n",
    "                                diffs[w_list][dec_1][dec_2].append(abs(dists[w_list][dec_2][fword_1][fword_2] - dists[w_list][dec_1][fword_1][fword_2]))\n",
    "                            except:\n",
    "                                continue\n",
    "                    diffs[w_list][dec_1][dec_2] = np.mean(diffs[w_list][dec_1][dec_2])\n",
    "        #df = pd.DataFrame()\n",
    "        diffs[\"f_words\"] = diffs[\"f_words\"][\"1900\"]\n",
    "        diffs[\"rand_words\"] = diffs[\"rand_words\"][\"1900\"]\n",
    "        return pd.DataFrame(diffs) \n",
    "    \n",
    "    def avg_distance(self, n=50): #e.g. self.norm_matrix[\"decade\"]\n",
    "        print(\"Calculating average distance...\")\n",
    "        self.dists = {dec:[] for dec, wv in self.wvs.items()}\n",
    "        for dec, norm_matrix in self.norm_matrix.items():\n",
    "            rand_inds = [random.randint(0, norm_matrix.shape[0]) for i in range(n)]\n",
    "            for ind_1 in rand_inds:\n",
    "                for ind_2 in rand_inds:\n",
    "                    self.dists[dec].append(np.linalg.norm(norm_matrix[ind_1] - norm_matrix[ind_2]))\n",
    "            self.dists[dec] = [el for el in self.dists[dec] if not pd.isna(el)]\n",
    "            self.dists[dec] = statistics.mean(self.dists[dec])\n",
    "        self.dists = pd.DataFrame(self.dists, index=[\"Mean distance\"])\n",
    "        return self.dists\n",
    "             \n",
    "    def stereotype_through_time(self, word, word_list=[], type=\"tag\", select=\"a\", selectn=10, topn= 100): #INCOMPLETE\n",
    "        '''wvs is an ordered dict, domain_list is a list of words, type is type of tagging, \n",
    "        select is specifics of tag'''\n",
    "        self.stereotypes[word] = {}\n",
    "        if type == \"tag\":\n",
    "            df = {}\n",
    "            for decade, wv in self.wvs.items():\n",
    "                df[decade] = {i: \"\" for i in range(selectn)}\n",
    "                sims = vec_tools.most_similar_tag(word, wv, vec_tools.wn_tagger, topn=topn, selectn=selectn, select=select)\n",
    "                for i,sim in enumerate(sims):  \n",
    "                    df[decade][i] = sim\n",
    "        elif type == None: \n",
    "            df= {}\n",
    "            for decade, wv in self.wvs.items():\n",
    "                df[decade] = {i: \"\" for i in range(selectn)}\n",
    "                sims = vec_tools.most_similar_wlist(word, wv, word_list=False, topn=topn, selectn=selectn)\n",
    "                for i,sim in enumerate(sims):  \n",
    "                    df[decade][i] = sim[0]\n",
    "        else:\n",
    "            df= {}\n",
    "            for decade, wv in self.wvs.items():\n",
    "                df[decade] = {i: \"\" for i in range(selectn)}\n",
    "                sims = vec_tools.most_similar_wlist(word, wv, word_list, topn=topn, selectn=selectn)\n",
    "                for i,sim in enumerate(sims):  \n",
    "                    df[decade][i] = sim[0]\n",
    "        df = pd.DataFrame(df)\n",
    "        self.stereotypes[word] = df\n",
    "    \n",
    "    def word_charts_through_time(self, domain, domain_dic, dim_1, dim_2, dom_type=\"word_list\", title=False):\n",
    "        '''dims = list of two strings which refer to dimensions to be projected on'''\n",
    "        try:\n",
    "            os.makedirs(f\"G:/My Drive/KU/Thesis/Outputs/Graphs/{domain}_{dim_1}_{dim_2}\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        #Get stats on projections to align output graphs with one another\n",
    "        data_projs = {dim_1: [], dim_2: []}\n",
    "        stats = [\"min\", \"max\", \"mean\", \"median\", \"variance\", \"dev\"]\n",
    "        chart_vals = {stat : {dim: 0 for dim in [dim_1, dim_2]} for stat in stats}\n",
    "                      \n",
    "        if dom_type == \"word_dict\":\n",
    "              #  print(domain_dic[domain])\n",
    "            word_list = [word for cat in domain_dic[domain].keys() for word in domain_dic[domain][cat]]\n",
    "        else:\n",
    "            word_list = [word for word in domain_dic[domain]]\n",
    "                     \n",
    "        for dim in [dim_1, dim_2]:\n",
    "            for dec, wv in self.wvs.items():\n",
    "                for word in word_list: \n",
    "                    try:\n",
    "                        ind = wv.get_index(word.lower())\n",
    "                        proj = self.projs[dec][dim][ind]\n",
    "                        data_projs[dim].append(proj)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                #data_projs[dim][dec] = [val for val in data_projs[dim][dec] if np.isnan(val)==False] \n",
    "                #chart_vals[\"min\"][dim][dec] = min(data_projs[dim][dec])\n",
    "                #chart_vals[\"max\"][dim][dec] = max(data_projs[dim][dec])\n",
    "                #chart_vals[\"median\"][dim][dec] = statistics.median(data_projs[dim][dec])\n",
    "                #chart_vals[\"mean\"][dim][dec] = statistics.mean(data_projs[dim][dec])\n",
    "                #chart_vals[\"variance\"][dim][dec] = np.var(data_projs[dim][dec])\n",
    "            df = data_projs\n",
    "            chart_vals[\"min\"][dim] = min(df[dim])\n",
    "            chart_vals[\"max\"][dim] = max(df[dim])\n",
    "            chart_vals[\"median\"][dim] = statistics.median(df[dim])\n",
    "            chart_vals[\"mean\"][dim] = statistics.mean(df[dim])\n",
    "            chart_vals[\"variance\"][dim] = np.var(df[dim])\n",
    "        #Generate a chart for each decade\n",
    "        for dec, wv in self.wvs.items():\n",
    "            if not title:\n",
    "                try:\n",
    "                    os.mkdirs(f\"G:/My Drive/KU/Thesis/Outputs/Graphs/{domain}_{dim_1}_{dim_2}/\")\n",
    "                except:\n",
    "                    pass\n",
    "                fname = f\"G:/My Drive/KU/Thesis/Outputs/Graphs/{domain}_{dim_1}_{dim_2}/{self.coll}_{dec}.png\"\n",
    "            dim1_label = self.ants[dec][dim_1].columns[1] + \" <------ \" + dim_1 + \" ------> \" + self.ants[dec][dim_1].columns[0]\n",
    "            dim2_label = self.ants[dec][dim_2].columns[1] + \" <------ \" + dim_2 + \" ------> \" + self.ants[dec][dim_2].columns[0]\n",
    "            if dom_type == \"word_dict\":\n",
    "                vec_tools.chart_project_dict(proj_1=self.projs[dec][dim_1], \n",
    "                                    p1_label=dim1_label, \n",
    "                                    proj_2=self.projs[dec][dim_2], \n",
    "                                    p2_label=dim2_label,\n",
    "                                    title=fname, \n",
    "                                    domain_dic=domain_dic[domain], \n",
    "                                    wv=wv, \n",
    "                                    show=False,\n",
    "                                    dim_1_span=(chart_vals[\"min\"][dim_1],chart_vals[\"max\"][dim_1]), \n",
    "                                    dim_2_span= (chart_vals[\"min\"][dim_2],chart_vals[\"max\"][dim_2]))\n",
    "                                 #  dim_1_span=(chart_vals[\"min\"][dim_1][\"overall\"],chart_vals[\"max\"][dim_1][\"overall\"]), \n",
    "                                  #                 dim_2_span= (chart_vals[\"min\"][dim_2][\"overall\"],chart_vals[\"max\"][dim_2][\"overall\"]))\n",
    "          \n",
    "            else:\n",
    "                vec_tools.chart_project(proj_1=self.projs[dec][dim_1], \n",
    "                                        p1_label=dim1_label, \n",
    "                                        proj_2=self.projs[dec][dim_2], \n",
    "                                        p2_label=dim2_label,\n",
    "                                        title=fname, \n",
    "                                        word_list=domain_dic[domain], \n",
    "                                        wv=wv, \n",
    "                                        show=False,\n",
    "                                       dim_1_span=(chart_vals[\"min\"][dim_1],chart_vals[\"max\"]), \n",
    "                                                   dim_2_span= (chart_vals[\"min\"][dim_2],chart_vals[\"max\"][dim_2]))\n",
    "    def chart_iterate(self, dims, doms, domain_dic, dom_type):\n",
    "        for i, dim_1 in enumerate(dims):\n",
    "            for dim_2 in dims_of_interest[i+1:]:\n",
    "                for domain, word_list in domain_dic.items():\n",
    "                    if domain not in doms:\n",
    "                        continue\n",
    "                    print(f\"Charting domain {domain} against dims ({dim_1} x {dim_2})\")\n",
    "                    self.word_charts_through_time(domain=domain, domain_dic=domain_dic, dom_type=dom_type, dim_1=dim_1, dim_2=dim_2, title=False)\n",
    "                # print(f\"{fname} SAVED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = \"histwords_engall\"#\"gb_12_18_02\"#\n",
    "#input_dir = f\"D:/google_ngrams/vectors/{coll}\"\n",
    "dims = [\"affluence\", \"cultivation\", \"status\", \"gender\", \"race\", \"morality\", \"education\"]\n",
    "histwords_iter = AllDecsIterator(coll, dims, kv=True, test=False)\n",
    "histwords_iter.iterate()\n",
    "#dists = iterator.stability_through_time()\n",
    "#iterator.avg_distance(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d5a8c9",
   "metadata": {},
   "source": [
    "## Chart through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b440a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dims_of_interest = [\"affluence\",  \"cultivation\" ,\"status\"]#\"race\",\n",
    "#domains: \n",
    "groups_of_interest = [\"Iso_occupations\"]\n",
    "doms_of_interest = [\"goc_genres\", \"occupations1950\", \"clothing\", \"emotion\", \"housing\", \"sports\", \"popular-music-types\", \"emotions\", \"genres\", \"places of entertainment\", \"types-of-vehicle\"]\n",
    "histwords_iter.chart_iterate(dims = dims_of_interest, doms=groups_of_interest, domain_dic=domain_dic, dom_type=\"word_dict\")\n",
    "#for i, dim_1 in enumerate(dims_of_interest):\n",
    " #   for dim_2 in dims_of_interest[i+1:]:\n",
    "  #      for domain, word_list in domain_dic.items():\n",
    "   #         if domain not in groups_of_interest:\n",
    "    #            continue\n",
    "     #       print(f\"Charting domain {domain} against dims ({dim_1} x {dim_2})\")\n",
    "      #      iterator.word_charts_through_time(domain=domain, dom_type=\"word_dict\", dim_1=dim_1, dim_2=dim_2, title=False)\n",
    "#coha_all_decs.word_charts_through_time(word_list=word_list, dim_1=\"affluence\", dim_2=\"gender\", title=\"occupations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf187b9",
   "metadata": {},
   "source": [
    "## Stereotype through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereos = {}\n",
    "dims\n",
    "#for occ in domain_dic[\"occupations1950\"]:\n",
    "   # histwords_iter.stereotype_through_time(occ, word_list=[], type=\"tag\", select=\"a\", selectn=10, topn= 100): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efedd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "occs = [\"executive\", \"manager\", \"director\", \"leader\", \"president\", \"coach\", \"boss\", \"chief\", \"ceo\"]\n",
    "u = [\"consultant\", \"adviser\", \"advisor\", \"customer\", \"entrepreneur\", \"expert\"]\n",
    "ns_words = [\"network\", \"networks\", \"networking\", \n",
    "         \"innovation\", \"innovative\", \"innovate\", \"create\", \"creative\", \"creativity\", \n",
    "         \"inspiration\", \"inspire\", \"inspirational\", \"genius\", \"invent\", \"inventor\", \n",
    "         \"disruptive\", \"bureaucracy\", \"bureaucrat\", \"decentralized\",\n",
    "         'decentralization','meritocracy','objectives','cadres','networks','project','vision', #projective city\n",
    "          'streamlined','slimmed','lean','leader','reengineering','flexible','innovative', \"communicative\",\n",
    "          'proficient','manager','coach','catalyst','visionary','inspriation','expert','operatives',\n",
    "          'toyotism','outward','fulfilment','autonomy','discovery','enrichment','learning','spontaneity',\n",
    "          'spectacle','reticular','alliance',\n",
    "         'Engaged','Engaging','Mobile','Enthusiastic','Involved','Flexible', #cond great man\n",
    "         'Adaptable','Versatile','Employable','Autonomous','Tolerant']\n",
    "[\"adjectives_appearance.txt\",  'adjectives_appearance.txt',\n",
    " 'adjectives_intelligencegeneral.txt', 'adjectives_otherization.txt', 'adjectives_princeton.txt',\n",
    " 'adjectives_sensitive.txt', 'adjectives_williamsbest.csv', 'adjectives_williamsbest.txt',\n",
    " 'personalitytraits_original.txt']\n",
    "\n",
    "occ = \"business\"\n",
    "wl = domain_dic[\"personalitytraits_original\"]# domain_dic[\"vices\"] + domain_dic[\"virtues\"]\n",
    "histwords_iter.stereotype_through_time(occ, word_list=wl, type=\"word_list\", select=\"a\", selectn=30, topn= 5000)\n",
    "histwords_iter.stereotypes[occ]\n",
    "for dec, wv in histwords_iter.wvs.items():\n",
    "    print(dec, vec_tools.vector_angle(wv[\"executive\"], wv[\"manager\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "ws = []\n",
    "h = \" Engaged, Engaging, Mobile, Enthusiastic, Involved, Flexible, Adaptable, Versatile, Employable, Autonomous, Tolerant, Employabilit\"\n",
    "for w in h.split():\n",
    "    for i,l in enumerate(w):\n",
    "        if l in string.punctuation:\n",
    "            ws.append(w[:i])\n",
    "            i = True\n",
    "            break\n",
    "    if i == False:\n",
    "        ws.append(w)\n",
    "        continue\n",
    "    i = False\n",
    "ws\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tools.most_similar_tag(word, wv, vec_tools.wn_tagger, topn=100, selectn=selectn, select=select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f87831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vec_tools\n",
    "vec_tools.most_similar_wlist(\"executive\", wv, word_list=wl, dim=False, topn=10000, selectn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3eb51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word = \"artist\"\n",
    "histwords_iter.stereotype_through_time(word, type=\"word_list\", word_list=domain_dic[\"personalitytraits_original\"], selectn=20, topn= 1000)\n",
    "histwords_iter.stereotype_through_time(word, type=\"word_list\", word_list=ns_words, selectn=30, topn= 10000)\n",
    "histwords_iter.stereotypes[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd151baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "histwords_iter.norm_matrix[\"1990\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59415a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dic[\"Iso_occupations\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = histwords_iter\n",
    "word = \"network\"\n",
    "wlist = domain_dic[\"Iso_occupations\"][\"Professional\"]\n",
    "\n",
    "wlist_projs  = {dim: {dec: [] for dec, wv in self.wvs.items()} for dim in self.dims}\n",
    "word_projs = {dim: {} for dim in self.dims}\n",
    "for dec, wv in self.wvs.items():\n",
    "    for dim in self.dims:\n",
    "        for word in wlist: \n",
    "            ind = wv.get_index(word.lower())\n",
    "            proj = self.projs[dec][dim][ind]\n",
    "            if pd.isna(proj):\n",
    "                continue\n",
    "            wlist_projs[dim][dec].append(proj)\n",
    "           # print(dec, dim, word, proj)\n",
    "        wlist_projs[dim][dec] = np.mean(wlist_projs[dim][dec])\n",
    "        ind = wv.get_index(word.lower())\n",
    "        proj = self.projs[dec][dim][ind]\n",
    "        word_projs[dim][dec] = proj\n",
    "df = pd.DataFrame(wlist_projs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "df.plot.line()\n",
    "df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = domain_dic[\"occupations1950\"][:7]\n",
    "word_projs = {word: {} for word in word_list}\n",
    "year_1, year_2 = [\"1900\", \"1990\"]\n",
    "dim = \"affluence\"\n",
    "\n",
    "for dec in [year_1, year_2]:\n",
    "    for word in word_list:\n",
    "        ind = self.wvs[dec].get_index(word.lower())\n",
    "        proj = self.projs[dec][dim][ind]\n",
    "        word_projs[word][dec] = proj\n",
    "df = pd.DataFrame(word_projs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "df.plot.line()\n",
    "#df.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a40a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line_polar(df, r=\"frequency\", theta=\"direction\", color=\"strength\", line_close=True,\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"plotly_dark\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5c71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = pd.DataFrame(df.stack()).reset_index()\n",
    "n.columns = [\"Decade\", \"Dimension\", \"Projection\"]\n",
    "px.line_polar(n, r=\"Projection\", theta=\"Dimension\", color=\"Decade\", line_close=True,\n",
    "                    color_discrete_sequence=px.colors.sequential.Plasma_r,\n",
    "                    template=\"ggplot2\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c2ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
