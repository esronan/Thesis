{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6ebaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim import downloader\n",
    "import gzip \n",
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75109f1",
   "metadata": {},
   "source": [
    "# Create iterative embedding evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e323985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eval_embeddings():\n",
    "    def __init__(self, dir, files, dl=False):\n",
    "        self.fils = files\n",
    "        self.dl = dl\n",
    "        #Change directory\n",
    "        os.chdir(dir)\n",
    "\n",
    "    def load_wv(self, fil):\n",
    "        if self.dl == False:\n",
    "            if os.path.isfile(fil):\n",
    "                model = gensim.models.Word2Vec.load(fil)\n",
    "                return model.wv\n",
    "            else: \n",
    "                print(f\"{fil} embeddings do not exist!\")\n",
    "                return 0\n",
    "        else: \n",
    "            model = api.load(fil)\n",
    "            return model\n",
    "        \n",
    "    def iterate(self, fils=None):\n",
    "        self.evals = {}\n",
    "        for fil in self.fils:\n",
    "            wv = self.load_wv(fil)\n",
    "            if wv == 0: #load_wv returns wv if embeddings don't exist\n",
    "                continue\n",
    "            else:\n",
    "                self.evals[fil] = {} #create dic for decade\n",
    "                self.eval_embed(wv, fil)\n",
    "        self.evals_df = pd.DataFrame(self.evals)\n",
    "               \n",
    "    def eval_embed(self, wv, fil):\n",
    "        print(f\"Starting evaluation for {fil}\")\n",
    "        # Evaluate one set of embeddings (for one decade) - scores stored under \"analogy_score\", and \"word_pair_pearson/spearman\"\n",
    "        analog = wv.evaluate_word_analogies('C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/questions-words.txt')\n",
    "        word_pairs = wv.evaluate_word_pairs('C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/wordsim353.tsv')\n",
    "        self.evals[fil][\"analogy_score\"] = analog[0]\n",
    "        self.evals[fil][\"word_pair_pearson\"]= word_pairs[0] #tuple with correlation score & 2-tailed p-value\n",
    "        self.evals[fil][\"word_pair_spearman\"]= word_pairs[1]#tuple with correlation score & 2-tailed p-value\n",
    "        print(f\"{fil} embeddings evaluated.\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6531c",
   "metadata": {},
   "source": [
    "# Evaluate all decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77aa1a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_6280/3362059211.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6280/3362059211.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    year_files = ['vectors-'+str(1900+*i)+'-ngram' for i in range(100)]\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#get filenames\n",
    "year_files = ['vectors-'+str(1900+*i)+'-ngram' for i in range(100)]\n",
    "#run evaluator\n",
    "evaluator = eval_embeddings(dir = \"D:/google_ngrams/vectors/vectors_per_year\", files = year_files, dl=False)\n",
    "#evaluator.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb07cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filenames\n",
    "year_files = ['w2vmodel_ng5_'+str(1900+10*i)+'_full' for i in range(10)]\n",
    "#run evaluator\n",
    "evaluator = eval_embeddings(dir = \"D:/google_ngrams/vectors/gb_12_vectors_1\", files = decade_files, dl=False)\n",
    "#evaluator.iterate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed896799",
   "metadata": {},
   "source": [
    "# Information on other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fa844",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = api.info()\n",
    "for corpus_name, corpus_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "            corpus_data['description'][:10] + '...',\n",
    "        )\n",
    "    )\n",
    "corps = [corpus_name for corpus_name, corpus_data in sorted(info['models'].items())]\n",
    "print(corps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887fede",
   "metadata": {},
   "source": [
    "# Evaluate other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d88b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for conceptnet-numberbatch-17-06-300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6280/3741755860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexternal_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/google_ngrams/vectors/gb_12_vectors_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexternal_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mexternal_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6280/3787468420.py\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self, fils)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#create dic for decade\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6280/3787468420.py\u001b[0m in \u001b[0;36meval_embed\u001b[1;34m(self, wv, fil)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Evaluate one set of embeddings (for one decade) - scores stored under \"analogy_score\", and \"word_pair_pearson/spearman\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0manalog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_word_analogies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/questions-words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mword_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_word_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/wordsim353.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"analogy_score\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"word_pair_pearson\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mword_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#tuple with correlation score & 2-tailed p-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mevaluate_word_pairs\u001b[1;34m(self, pairs, delimiter, restrict_vocab, case_insensitive, dummy4unknown)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_key_to_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m         \u001b[0mspearman\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mpearson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdummy4unknown\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[0moov_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moov\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity_gold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   4014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4015\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4016\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x and y must have length at least 2.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4018\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "external_models = ['conceptnet-numberbatch-17-06-300', 'fasttext-wiki-news-subwords-300', 'glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50', 'word2vec-google-news-300'] #'__testing_word2vec-matrix-synopsis',  'word2vec-ruscorpora-300' \n",
    "       \n",
    "\n",
    "external_eval = eval_embeddings(dir = \"D:/google_ngrams/vectors/gb_12_vectors_1\", files=external_models, dl=True)\n",
    "external_eval.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174027eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a2cb2",
   "metadata": {},
   "source": [
    "# Single case (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e54846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing single case\n",
    "\n",
    "#load word vectors from model\n",
    "print(os.listdir())\n",
    "year = \"-cl\"\n",
    "fil = f'w2vmodel_ng5_{year}_full'\n",
    "model = gensim.models.Word2Vec.load(fil)\n",
    "wv = model.wv\n",
    "#evaluate\n",
    "evals = {}\n",
    "evals[year] = {}\n",
    "analog = model.wv.evaluate_word_analogies('C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/questions-words.txt')\n",
    "word_pairs = model.wv.evaluate_word_pairs('C:/ProgramData/Anaconda3/Lib/site-packages/gensim/test/test_data/wordsim353.tsv')\n",
    "evals[year][\"analogy_score\"] = analog[0]\n",
    "for section in analog[1]:\n",
    "    try:\n",
    "        evals[f\"analogy_{section['section']}\"] = 100*len(section[\"correct\"])/(len(section[\"incorrect\"])+len(section[\"correct\"]))\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "evals[year][\"word_pair_pearson\"]=word_pairs[0] #tuple with correlation score & 2-tailed p-value\n",
    "evals[year][\"word_pair_spearman\"]=word_pairs[1]#tuple with correlation score & 2-tailed p-value\n",
    "print(f\"{fil} embeddings evaluated.\")\n",
    "evals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
