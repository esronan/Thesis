{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HLYbERwurApA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim import downloader\n",
    "import gzip \n",
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "import os\n",
    "import tqdm.notebook as tq\n",
    "import mgzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bBgIiTcP8JJK"
   },
   "outputs": [],
   "source": [
    "class ngram_extractor_lite():\n",
    "    def __init__(self, filname, limit=None):\n",
    "        self.limit = limit\n",
    "        self.filname = filname\n",
    "        start = time()\n",
    "        print(self.filname)\n",
    "        self.ngrams = []\n",
    "        print(\"Loading to memory...\")\n",
    "        with mgzip.open(self.filname, \"rt\", encoding=\"utf-8\", thread= 4) as fil: #just changed from r to rt so that it reads the csv separations\n",
    "        # with gensim.utils.smart_open(os.path.join(self.dir_path, filname)) as fil:\n",
    "            j = 0\n",
    "            for line in tq.tqdm(itertools.islice(fil, self.limit)):\n",
    "                line = gensim.utils.to_unicode(line).split(\"\\t\")\n",
    "                ngram = line[0].split()\n",
    "                match_count = int(line[-1])\n",
    "                self.ngrams.append((ngram, match_count))\n",
    "                \n",
    "            print(f\"Time taken: {time()-start}\")\n",
    "    def __iter__(self):\n",
    "        print(\"Iterating...\")\n",
    "        start = time()\n",
    "        for ngram in tq.tqdm(self.ngrams):\n",
    "            for i in range(ngram[1]):\n",
    "                yield ngram[0]\n",
    "        print(f\"Time taken: {time()-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterable version - one epoch at at time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Z_yE02XL1Ayp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1500.gz', '1510.gz', '1520.gz', '1530.gz', '1540.gz', '1550.gz', '1560.gz', '1570.gz', '1580.gz', '1590.gz', '1600.gz', '1610.gz', '1620.gz', '1630.gz', '1640.gz', '1650.gz', '1660.gz', '1670.gz', '1680.gz', '1690.gz', '1700.gz', '1710.gz', '1720.gz', '1730.gz', '1740.gz', '1750.gz', '1760.gz', '1770.gz', '1780.gz', '1790.gz', '1800.gz', '1810.gz', '1820.gz', '1830.gz', '1840.gz', '1850.gz', '1860.gz', '1870.gz', '1880.gz', '1890.gz', '1900.gz', '1910.gz', '1920.gz', '1930.gz', '1940.gz', '1950.gz', '1960.gz', '1970.gz', '1980.gz', '1990.gz', '2000.gz']\n",
      "1820.gz\n",
      "Loading to memory...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f55ed842614460f9deac4b1b89c10c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 10.00536823272705\n",
      "Iterating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f9e578912c4451adc6e7a8a08e07cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6876/957080022.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocab built.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'w2vmodel_ng5_'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mfilname\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vocab\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[0;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         total_words, corpus_count = self.scan_vocab(\n\u001b[0m\u001b[0;32m    488\u001b[0m             corpus_iterable=corpus_iterable, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[0mcorpus_iterable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         logger.info(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[1;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                 \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m             \u001b[0mtotal_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert gensim.models.word2vec.FAST_VERSION > -1 # check that it is the latest version of Word2vecngrams = ngram_extractor(dir_path, save_path, start_yr, end_yr, limit)\n",
    "\n",
    "#an iterable version, so each iteration is ssaved (perhaps for each file there should be a save?):\n",
    "epochs = 5\n",
    "vocab = False\n",
    "completed = 0\n",
    "method = 1 # 1  sg, cbow = 0\n",
    "\n",
    "size = 300 # vector size\n",
    "min_count = 25\n",
    "data_dir = \"D:/google_ngrams/processed_data/gb_12_min_100\"\n",
    "out_dir = \"D:/google_ngrams/vectors/gb_12_min_100/\"\n",
    "os.chdir(data_dir)\n",
    "print(os.listdir())\n",
    "filname = \"1820.gz\"\n",
    "ngrams = ngram_extractor_lite(filname=filname)\n",
    "\n",
    "for i in range(epochs-completed):\n",
    "    if vocab:\n",
    "        model = Word2Vec.load('../vectors/us_12/w2vmodel_ng5_' + filname  + \"_\" + str(\"vocab\"))\n",
    "        print(\"Vocab loaded.\")\n",
    "    elif completed != 0:\n",
    "        model = Word2Vec.load('w2vmodel_ng5_' + filname + \"_\" + str(completed))\n",
    "        print(\"Model loaded.\")\n",
    "    elif i == 0:\n",
    "        model = gensim.models.word2vec.Word2Vec(sg=method, vector_size=size, window=5, min_count=25, workers=10, hs=0, negative=8, epochs=1)\n",
    "        model.build_vocab(ngrams)\n",
    "        print(\"Vocab built.\")\n",
    "        model.save('w2vmodel_ng5_'+ filname +'_' + str(\"vocab\"))\n",
    "    model.train(ngrams, total_examples = model.corpus_count, epochs = 1)\n",
    "    model.save('w2vmodel_ng5_'+ filname +'_' + str(completed+i+1))\n",
    "    print(\"Epoch \" + str(completed + i + 1) + \" completed.\")\n",
    "#5megabytes took 10 sec + 11*5 = 1 hour. 50mb would take 5 hours. 500mb 50 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gensim.models.word2vec.FAST_VERSION > -1 # check that it is the latest version of Word2vecngrams = ngram_extractor(dir_path, save_path, start_yr, end_yr, limit)\n",
    "\n",
    "#an iterable version, so each iteration is ssaved (perhaps for each file there should be a save?):\n",
    "epochs = 5\n",
    "vocab = True\n",
    "completed = 0\n",
    "method = 1 # 1  sg, cbow = 0\n",
    "size = 300 # vector size\n",
    "min_count = 25\n",
    "data_dir = \"D:/google_ngrams/us_12_latest8\"\n",
    "out_dir = \"D:/google_ngrams/vectors/us_12/\"\n",
    "os.chdir(data_dir)\n",
    "print(os.listdir())\n",
    "filname = \"1920.gz\"\n",
    "ngrams = ngram_extractor_lite(filname=filname)\n",
    "for i in range(epochs-completed):\n",
    "    if vocab:\n",
    "        model = Word2Vec.load('../vectors/us_12/w2vmodel_ng5_' + filname + \"_\" + str(\"vocab\"))\n",
    "        print(\"Vocab loaded.\")\n",
    "    elif completed != 0:\n",
    "        model = Word2Vec.load('w2vmodel_ng5_' + filname + \"_\" + str(completed))\n",
    "        print(\"Model loaded.\")\n",
    "    elif i == 0:\n",
    "        model = gensim.models.word2vec.Word2Vec(sg=method, vector_size=size, window=5, min_count=25, workers=10, hs=0, negative=8, epochs=1)\n",
    "        model.build_vocab(ngrams)\n",
    "        print(\"Vocab built.\")\n",
    "        model.save('w2vmodel_ng5_'+ filname +'_' + str(\"vocab\"))\n",
    "    model.train(ngrams, total_examples = model.corpus_count, epochs = 1)\n",
    "    model.save('w2vmodel_ng5_'+ filname +'_' + str(completed+i+1))\n",
    "    print(\"Epoch \" + str(completed + i + 1) + \" completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "word2vec_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
