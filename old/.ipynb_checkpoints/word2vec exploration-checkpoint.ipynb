{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4804a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim import downloader\n",
    "import gzip \n",
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06dbdd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'w2vmodel_ng5_1910.gz_5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6872/1783529791.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#load word vectors from model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mwv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1928\u001b[0m         \"\"\"\n\u001b[0;32m   1929\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1930\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1931\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1932\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \"\"\"\n\u001b[1;32m-> 1459\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'w2vmodel_ng5_1910.gz_5'"
     ]
    }
   ],
   "source": [
    "dir = \"D:/google_ngrams/processed_data/\"\n",
    "col = \"gb_12_min_100_fix7/\" #\"us_12\" \"vectors_per_year\", \"gb_12_vectors_incomplete\"\n",
    "year = 1910\n",
    "fil = f'w2vmodel_ng5_{year}.gz_5'\n",
    "#fil = \"w2vmodel_ng5_1900_full\"\n",
    "\n",
    "os.chdir(dir + col)\n",
    "\n",
    "#load word vectors from model\n",
    "model = gensim.models.Word2Vec.load(fil)\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb486744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/27887 is the\n",
      "word #1/27887 is of\n",
      "word #2/27887 is ,\n",
      "word #3/27887 is .\n",
      "word #4/27887 is to\n",
      "word #5/27887 is in\n",
      "word #6/27887 is and\n",
      "word #7/27887 is a\n",
      "word #8/27887 is it\n",
      "word #9/27887 is is\n",
      "27887\n",
      "Similarity:  0.14393878\n",
      "5 most similar to nationality:  [('suitability', 0.5212187170982361), ('reliability', 0.5197199583053589), ('legitimacy', 0.5139038562774658), ('practicability', 0.5035502314567566), ('trustworthiness', 0.5009819865226746), ('feasibility', 0.49852579832077026), ('advisability', 0.4948616921901703), ('custome', 0.49454864859580994), ('fellowmen', 0.49437764286994934), ('predominance', 0.4934661090373993), ('contractions', 0.4868064820766449), ('shrinking', 0.4863063395023346), ('admissibility', 0.4863017499446869), ('lawfulness', 0.48541730642318726), ('desirability', 0.4836220443248749), ('shifting', 0.48181256651878357), ('spokesman', 0.47678911685943604), ('munificence', 0.4754294157028198), ('liberality', 0.4745745360851288), ('antagonists', 0.47199422121047974), ('caprice', 0.46935221552848816), ('capabilities', 0.46902549266815186), ('bestowal', 0.4656720459461212), ('commandement', 0.4636029303073883), ('exactions', 0.4605575203895569), ('inadequacy', 0.45971325039863586), ('stigmas', 0.4596213698387146), ('threats', 0.4593147337436676), ('subversion', 0.45885032415390015), ('closure', 0.45818090438842773), ('qualitie', 0.4567350149154663), ('partisans', 0.45610618591308594), ('personification', 0.4555967450141907), ('possibilities', 0.45429256558418274), ('archway', 0.45275965332984924), ('diction', 0.45244336128234863), ('pretensions', 0.452343225479126), ('originator', 0.4520329535007477), ('disruption', 0.45188841223716736), ('caste', 0.45162662863731384), ('rapacity', 0.4515044093132019), ('irruption', 0.4511854946613312), ('laird', 0.4507572054862976), ('rattling', 0.45065540075302124), ('commaundement', 0.45017534494400024), ('puritan', 0.44975268840789795), ('ingenuity', 0.4492403268814087), ('creaking', 0.44877269864082336), ('connivance', 0.4480985999107361), ('defection', 0.44748029112815857), ('repulse', 0.44647881388664246), ('emissaries', 0.4460669755935669), ('panels', 0.44596144556999207), ('subsidence', 0.4459353983402252), ('surveillance', 0.44593340158462524), ('overflow', 0.44553032517433167), ('assailants', 0.4453061521053314), ('manes', 0.4445998966693878), ('insolence', 0.4439166784286499), ('veterans', 0.4437539875507355), ('fumes', 0.44358929991722107), ('attire', 0.4433096945285797), ('exhibitions', 0.4421233832836151), ('derision', 0.44136545062065125), ('thinness', 0.4413473606109619), ('rigours', 0.44132885336875916), ('transference', 0.44043001532554626), ('persistence', 0.43956297636032104), ('minion', 0.43900132179260254), ('tutelage', 0.43867164850234985), ('discomfort', 0.43833333253860474), ('consternation', 0.43762969970703125), ('credibility', 0.43758276104927063), ('guiding', 0.4373679757118225), ('fowls', 0.437337726354599), ('wiles', 0.43634718656539917), ('whereabouts', 0.435576468706131), ('authenticity', 0.4348915219306946), ('inroads', 0.43488186597824097), ('cooperation', 0.43478286266326904), ('designation', 0.43425920605659485), ('architrave', 0.43423473834991455), ('soundness', 0.4341726005077362), ('assaults', 0.4330930709838867), ('weakening', 0.43288344144821167), ('dissatisfaction', 0.432686448097229), ('fesole', 0.4324707090854645), ('attractiveness', 0.4323408603668213), ('genuineness', 0.4321677088737488), ('privity', 0.43183693289756775), ('losse', 0.43142348527908325), ('rigidity', 0.43116697669029236), ('inclusion', 0.43096452951431274), ('symbolism', 0.43054747581481934), ('spermatozoon', 0.42830991744995117), ('fatigues', 0.42824336886405945), ('suction', 0.42771387100219727), ('judgement', 0.4274798631668091), ('taurus', 0.42744314670562744), ('vastness', 0.42707547545433044)]\n"
     ]
    }
   ],
   "source": [
    "#check vocab\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")\n",
    "print(len(wv.index_to_key))\n",
    "\"specify words\"\n",
    "w1, w2 = \"nationality\", \"drunk\"\n",
    "#get a vector of one of the words\n",
    "#print(wv[w1])\n",
    "# calculate similarity between two different words\n",
    "print(\"Similarity: \", wv.similarity(w1, w2))\n",
    "#find most similar to w1 & w2, or least\n",
    "print(f\"5 most similar to {w1}: \", wv.most_similar(positive=[w1], topn=100))\n",
    "#find the odd one oute\n",
    "#wv.doesnt_match([list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0320cf1",
   "metadata": {},
   "source": [
    "Racist:\n",
    "\n",
    "fascist (same kind of person), quitter (unrelated), nationalist (same kind of person), psychopath (perhaps same kind of person), judgmental (an adjective describing this person), slob (fits with the stereotype), pervert (another negative person but not same  kind of person), marxist (the opposite - marxists are rarely terrorists), terrorist (the object of racism), apartheid (social structure that is this by design), leninist (also strange), troublemaker (right winger streotype), bullshitting (right wing stereotype), anarchist (strange), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73c0277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors-2000-ngram.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1220/3417065482.py:25: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "f = open(fil)\n",
    "dir = \"D:/google_ngrams/vectors/\"\n",
    "col = \"vectors_per_year/\" #\"us_12\"\n",
    "fil = os.listdir()[-2]\n",
    "print(fil)\n",
    "#i=0\n",
    "#for line in f.readlines():\n",
    "   # j = len(line.split())\n",
    "    #i+=1\n",
    "#print(i, j)\n",
    "    \n",
    "def line_prepender(filename, line):\n",
    "    with open(filename, 'r+') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        f.write(line.rstrip('\\r\\n') + '\\n' + content)   \n",
    "#line = \"48452 301\"\n",
    "#line_prepender(fil, line)\n",
    "\n",
    "glove_file = dir+col+fil\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "wv = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfa2fa",
   "metadata": {},
   "source": [
    "# Import antonym lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e84b1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rich_ant</th>\n",
       "      <th>poor_ant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rich</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>richer</td>\n",
       "      <td>poorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>richest</td>\n",
       "      <td>poorest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>affluence</td>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>advantaged</td>\n",
       "      <td>disadvantaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>affluent</td>\n",
       "      <td>destitute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>classy</td>\n",
       "      <td>beggarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>costly</td>\n",
       "      <td>economical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exorbitant</td>\n",
       "      <td>impecunious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>expensive</td>\n",
       "      <td>inexpensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exquisite</td>\n",
       "      <td>ruined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>extravagant</td>\n",
       "      <td>necessitous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flush</td>\n",
       "      <td>skint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>invaluable</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lavish</td>\n",
       "      <td>economical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>luxuriant</td>\n",
       "      <td>penurious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>luxurious</td>\n",
       "      <td>threadbare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>luxury</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>moneyed</td>\n",
       "      <td>unmonied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>opulent</td>\n",
       "      <td>indigent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>plush</td>\n",
       "      <td>threadbare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>posh</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>precious</td>\n",
       "      <td>cheap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>priceless</td>\n",
       "      <td>worthless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>privileged</td>\n",
       "      <td>underprivileged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>propertied</td>\n",
       "      <td>bankrupt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prosperous</td>\n",
       "      <td>unprosperous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>developed</td>\n",
       "      <td>underdeveloped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>solvency</td>\n",
       "      <td>insolvency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>successful</td>\n",
       "      <td>unsuccessful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sumptuous</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>swanky</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>opulent</td>\n",
       "      <td>needy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>upscale</td>\n",
       "      <td>squalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>valuable</td>\n",
       "      <td>valueless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wealthy</td>\n",
       "      <td>impoverished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ritzy</td>\n",
       "      <td>ramshackle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>opulence</td>\n",
       "      <td>indigence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>solvent</td>\n",
       "      <td>insolvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>moneyed</td>\n",
       "      <td>moneyless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rich</td>\n",
       "      <td>penniless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>affluence</td>\n",
       "      <td>penury</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rich_ant         poor_ant\n",
       "0          rich             poor\n",
       "1        richer           poorer\n",
       "2       richest          poorest\n",
       "3     affluence          poverty\n",
       "4    advantaged    disadvantaged\n",
       "5      affluent        destitute\n",
       "6        classy         beggarly\n",
       "7        costly       economical\n",
       "8    exorbitant      impecunious\n",
       "9     expensive      inexpensive\n",
       "10    exquisite           ruined\n",
       "11  extravagant      necessitous\n",
       "12        flush            skint\n",
       "13   invaluable            cheap\n",
       "14       lavish       economical\n",
       "15    luxuriant        penurious\n",
       "16    luxurious       threadbare\n",
       "17       luxury            cheap\n",
       "18      moneyed         unmonied\n",
       "19      opulent         indigent\n",
       "20        plush       threadbare\n",
       "21         posh            plain\n",
       "22     precious            cheap\n",
       "23    priceless        worthless\n",
       "24   privileged  underprivileged\n",
       "25   propertied         bankrupt\n",
       "26   prosperous     unprosperous\n",
       "27    developed   underdeveloped\n",
       "28     solvency       insolvency\n",
       "29   successful     unsuccessful\n",
       "30    sumptuous            plain\n",
       "31       swanky            basic\n",
       "32      opulent            needy\n",
       "33      upscale          squalid\n",
       "34     valuable        valueless\n",
       "35      wealthy     impoverished\n",
       "36        ritzy       ramshackle\n",
       "37     opulence        indigence\n",
       "38      solvent        insolvent\n",
       "39      moneyed        moneyless\n",
       "40         rich        penniless\n",
       "41    affluence           penury"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affluence_ants = pd.read_csv(\"G:/My Drive/KU/Thesis/word_pairs/affluence_pairs.csv\", header = None, names = (\"rich_ant\", \"poor_ant\"))\n",
    "race_ants = pd.read_csv(\"G:/My Drive/KU/Thesis/word_pairs/race_pairs.csv\", header = None, names = (\"black_ant\", \"white_ant\"))\n",
    "gender_ants = pd.read_csv(\"G:/My Drive/KU/Thesis/word_pairs/gender_pairs.csv\", header = None, names = (\"male_ant\", \"female_ant\"))\n",
    "affluence_ants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb7c34",
   "metadata": {},
   "source": [
    "# Make word dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b002fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dim(wv, ant_df):\n",
    "    dims = ant_df.shape\n",
    "    diffs = []\n",
    "    for i in range(dims[0]):\n",
    "        try:\n",
    "            pos_wv = wv[ant_df.iloc[i,0].lower()]\n",
    "            neg_wv = wv[ant_df.iloc[i,1].lower()]\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "            continue\n",
    "        diff = pos_wv - neg_wv\n",
    "        diffs.append(diff)\n",
    "    dimension = sum(diffs)/dims[0]\n",
    "    return dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e58ad2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Key 'classy' not present\"\n",
      "\"Key 'impecunious' not present\"\n",
      "\"Key 'necessitous' not present\"\n",
      "\"Key 'skint' not present\"\n",
      "\"Key 'penurious' not present\"\n",
      "\"Key 'moneyed' not present\"\n",
      "\"Key 'posh' not present\"\n",
      "\"Key 'unprosperous' not present\"\n",
      "\"Key 'solvency' not present\"\n",
      "\"Key 'swanky' not present\"\n",
      "\"Key 'upscale' not present\"\n",
      "\"Key 'ritzy' not present\"\n",
      "\"Key 'indigence' not present\"\n",
      "\"Key 'moneyed' not present\"\n"
     ]
    }
   ],
   "source": [
    "gen_dim = make_dim(wv, gender_ants)\n",
    "race_dim = make_dim(wv, race_ants)\n",
    "aff_dim = make_dim(wv, affluence_ants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7086a1b",
   "metadata": {},
   "source": [
    "# Find angles between words & dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b9a22c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6226958"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vector_angle(v1, v2):\n",
    "    v1_norm = v1/np.linalg.norm(v1)\n",
    "    v2_norm = v2/np.linalg.norm(v2)\n",
    "    dot = np.dot(v1_norm, v2_norm)\n",
    "    angle = np.arccos(dot)\n",
    "    return angle\n",
    "vector_angle(gen_dim, race_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff1755",
   "metadata": {},
   "source": [
    "# Project vector onto dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5d4cdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.loadtxt(os.listdir()[-2], usecols = range(1,301))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6da9a10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([        'fawn', 'homomorphism',     'schlegel',      'nunnery',\n",
       "              'askew',     'ginzburg',        'woods',      'clotted',\n",
       "            'spiders',      'hanging',\n",
       "       ...\n",
       "        'perfections',          'gan',      'rotting',        'emery',\n",
       "           'baumrind',        'emerg',    'northerly',       'primus',\n",
       "            'expands',      'jawbone'],\n",
       "      dtype='object', length=48452)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.listdir()[-2], header=None, names = range(1,301), index_col=0, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8dc619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_matrix(matrix):\n",
    "    for i, row in enumerate(matrix):\n",
    "        matrix[i] = row/np.linalg.norm(row)\n",
    "    return matrix\n",
    "\n",
    "norm_matrix = norm_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "64583452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1220/36916314.py:8: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  dic = df.T.to_dict()\n"
     ]
    }
   ],
   "source": [
    "def project(dim, wv):\n",
    "    return np.dot(wv, dim)\n",
    "gen_proj = project(gen_dim, norm_matrix)\n",
    "aff_proj = project(aff_dim, norm_matrix)\n",
    "race_proj = project(race_dim, norm_matrix)\n",
    "df[\"number\"] = range(1, len(df) + 1)\n",
    "df.T.head()\n",
    "dic = df.T.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9472cd",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd016734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chart_project(proj_1, proj_2, dic, domain):\n",
    "    datapoints = []\n",
    "    for item in domain:\n",
    "        ind = dic[item][\"number\"]\n",
    "        coords = (proj_1[ind], proj_2[ind])\n",
    "        datapoints.append(coords)\n",
    "    plt.plot(datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f1cc0",
   "metadata": {},
   "source": [
    "# Find top related words, POS tag, sentimental analysis, visualise "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
