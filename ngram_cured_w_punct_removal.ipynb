{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\My Drive\\\\KU\\\\Thesis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim import downloader\n",
    "import gzip \n",
    "import math\n",
    "import itertools\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format for ngram documents:**\n",
    "\n",
    "ngram TAB year TAB match_count TAB page_count TAB volume_count NEWLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel with mgzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning and deleting entries under 40 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_10516/1231472528.py, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_10516/1231472528.py\"\u001b[1;36m, line \u001b[1;32m65\u001b[0m\n\u001b[1;33m    if filname[0] = \"_\":\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import mgzip\n",
    "import string\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "#Differences with this one: it adds up the match count of all the years in a decade and writes one line per decade, \n",
    "# threshold is reduced to 25\n",
    "# gets rid of lines with punctuation\n",
    "\n",
    "class ParrNgramFiler():\n",
    "    def __init__(self, coll, out, dire, start_yr, end_yr, matchmin=25, test=False):\n",
    "        self.coll = coll\n",
    "        self.out = out\n",
    "        self.dir = dire\n",
    "        self.start_yr = start_yr\n",
    "        self.end_yr = end_yr\n",
    "        self.decades = [start_yr+i*10 for i in range((end_yr-start_yr)//10)]\n",
    "        self.matchmin = matchmin\n",
    "        self.exclist = string.punctuation + string.digits\n",
    "        self.punc = string.punctuation\n",
    "        self.lines = {}\n",
    "    \n",
    "    def write(self, ngram):\n",
    "        split = []\n",
    "        for word in ngram.lower().split():\n",
    "            word = word.split(\"_\")[0]\n",
    "            if word in self.punc:\n",
    "                continue\n",
    "            else:\n",
    "                split.append(word)\n",
    "        if len(split) < 5:\n",
    "            continue\n",
    "        else:\n",
    "            to_write = \" \".join(split + [\"\\t\" + str(match_count) + \"\\n\"]) #Get rid of POS tagging on end of words\n",
    "            if self.test != False:\n",
    "                 print(\"TO WRITE: \", to_write)\n",
    "            split = \" \".join(split)\n",
    "            self.write_dic[current_dec].write(split)\n",
    "        \n",
    "    def file(self): \n",
    "        os.chdir(f\"{self.dir}/raw_data/{self.coll}\")\n",
    "        self.write_dic = {}\n",
    "        self.size_dic = {}\n",
    "        self.lines = 0\n",
    "        if self.test:\n",
    "            try:\n",
    "                shutil.rmtree(f\"../{self.coll}_{self.out}/\")\n",
    "            except:\n",
    "                pass\n",
    "        os.makedirs(f\"{self.dir}/processed_data/{self.coll}_{self.out}/\")\n",
    "        for dec in self.decades:\n",
    "            fname = str(dec) + \".gz\"\n",
    "            self.write_dic[dec] = mgzip.open(f\"{self.dir}/processed_data/{self.coll}_{self.out}/\" + fname, \"wt\", encoding=\"utf-8\")\n",
    "        \n",
    "        #Try on specified no. files if testing\n",
    "        if self.test != False:\n",
    "            file_list = os.listdir()[:test]\n",
    "        else:\n",
    "            file_list = os.listdir()\n",
    "        \n",
    "        \n",
    "        for filname in tq.tqdm(file_list):\n",
    "            \n",
    "            #Skip over the POS tag files\n",
    "            if filname[0] = \"_\":\n",
    "                continue\n",
    "            \n",
    "            print(\"File: \", filname, f\", current time: {time()-start}, current lines: {self.lines}\")\n",
    "            #Open file with parallel gzip \n",
    "            with mgzip.open(f\"{self.dir}/raw_data/{self.coll}/\" + filname, \"rt\", encoding=\"utf-8\") as fil:\n",
    "                #Try to counteract \"not a gzipped file\" error\n",
    "                try:\n",
    "                    for i, line in enumerate(tq.tqdm(fil)):\n",
    "                        \n",
    "                        #count lines for printing after each file\n",
    "                        self.lines[fil] += 1\n",
    "                        \n",
    "                        #Split file at the tab\n",
    "                        line = gensim.utils.to_unicode(line).split(\"\\t\")\n",
    "                        \n",
    "                        #Get the year as integer, throw up an error if no year fuond\n",
    "                        try:\n",
    "                            year = int(line[1])\n",
    "                        except ValueError:\n",
    "                            print(\"Year error on line: \", line)\n",
    "                            continue\n",
    "                        \n",
    "                        #Get corresponding decade\n",
    "                        dec = int(str(year)[:-1] + \"0\")\n",
    "                        \n",
    "                        #Isolate ngram\n",
    "                        ngram = line[0]\n",
    "                        \n",
    "                        #Initialise values for decadising ngram data\n",
    "                        if i == 0:\n",
    "                            prev_ngram = ngram\n",
    "                            match_count = int(line[2])\n",
    "                            current_dec = dec\n",
    "                            continue\n",
    "                            \n",
    "                        #Get match count\n",
    "                        try: \n",
    "                            matches = int(line[2])\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error, line {i} -> {line}:\\n\", e)\n",
    "                            continue\n",
    "                        \n",
    "                        #Print first 1000 if in test mode\n",
    "                        if self.test != False:\n",
    "                            if i > self.test:\n",
    "                                print(\"\\nCurrent ngram: \", prev_ngram, \"\\nMatches: \", match_count, \"\\n Current Line: \", line)\n",
    "                            else:\n",
    "                                break\n",
    "                        \n",
    "                        #check current/previous ngram\n",
    "                        if prev_ngram == ngram:\n",
    "                            #check current/previous decade\n",
    "                            if dec == current_dec:\n",
    "                                match_count += matches\n",
    "                            #if not equal, \n",
    "                            else: \n",
    "                                if match_count > self.matchmin:\n",
    "                                    split = []\n",
    "                                    for word in ngram.lower().split():\n",
    "                                        word = word.split(\"_\")[0]\n",
    "                                        if word in self.punc:\n",
    "                                            continue\n",
    "                                        else:\n",
    "                                            split.append(word)\n",
    "                                    if len(split) < 5:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #to_write = \" \".join(split + [\"\\t\" + str(match_count) + \"\\n\"]) #Get rid of POS tagging on end of words\n",
    "                                        #print(\"TO WRITE: \", to_write)\n",
    "                                        print(split)\n",
    "                                        split = \" \".join(split)\n",
    "                                        self.write_dic[current_dec].write(split)\n",
    "                                        current_dec = dec\n",
    "                                        match_count = matches\n",
    "                                else:\n",
    "                                    current_dec = dec\n",
    "                                    match_count = matches\n",
    "\n",
    "                        else:\n",
    "                            if match_count > self.matchmin:\n",
    "                                split = []\n",
    "                                for word in ngram.lower().split():\n",
    "                                    word = word.split(\"_\")[0]\n",
    "                                    if word in self.punc:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        split.append(word)\n",
    "                                if len(split) < 5:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    print(split)\n",
    "                                    split = \" \".join(split)\n",
    "                                    self.write_dic[current_dec].write(split)\n",
    "                            prev_ngram = ngram\n",
    "                            match_count = matches\n",
    "                            current_dec = dec\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "        for dec in self.decades:\n",
    "            self.write_dic[dec].close()\n",
    "                    \n",
    "\n",
    "\n",
    "start = time()\n",
    "Filer = ParrNgramFiler(coll=\"gb_12\", out=\"min_100_test9\", dire=\"D:/google_ngrams\", start_yr=1500, end_yr=2010, matchmin=100)\n",
    "Filer.file(test=5)\n",
    "print(f\"Total time taken: {time()-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether each file iterated over writes more information to the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NgramFiler.size_dic\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
